{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load text from file\n",
    "def load_text(file_path, encoding='UTF-8'):\n",
    "    \n",
    "    docs = []\n",
    "    with open(file_path, 'r', encoding=encoding) as f:\n",
    "        for line in f:\n",
    "            docs.append(line.strip())\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get language code by fasttext\n",
    "def get_lang(docs, model_path, kmost=1):\n",
    "\n",
    "    lang_classifier = fastText.load_model(model_path)\n",
    "\n",
    "    return lang_classifier.predict(docs, kmost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save text to file\n",
    "def save_text(text, file_path, encoding='UTF-8'):\n",
    "    # write to output\n",
    "    with open(file_path, 'w', encoding=encoding) as f:\n",
    "        f.write('\\n'.join(text))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove duplicate pair\n",
    "def pair_deduplicate(doc_left, doc_right):\n",
    "    \n",
    "    doc_left_clean = []\n",
    "    doc_right_clean = []\n",
    "    \n",
    "    # already exist\n",
    "    doc_contain = set()\n",
    "    \n",
    "    for dl, dr in zip(doc_left, doc_right):\n",
    "        if (dl not in doc_contain) and (dr not in doc_contain):\n",
    "            doc_left_clean.append(dl)\n",
    "            doc_right_clean.append(dr)\n",
    "        \n",
    "        doc_contain.add(dl)\n",
    "        doc_contain.add(dr)\n",
    "        \n",
    "    print('remove duplicate from langauge pair')\n",
    "    print('from {0} to {1}'.format(len(doc_left), len(doc_left_clean)))\n",
    "    \n",
    "    return doc_left_clean, doc_right_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove mislength pair\n",
    "def pair_mislength(doc_left, doc_right, ratio=1.8, verbose=False):\n",
    "    \n",
    "    doc_left_clean = []\n",
    "    doc_right_clean = []\n",
    "    \n",
    "    for dl, dr in zip(doc_left, doc_right):\n",
    "        \n",
    "        ll = len(dl.split())\n",
    "        lr = len(dr.split())\n",
    "        \n",
    "        if (ll < lr*ratio) and (lr < ll*ratio):\n",
    "            doc_left_clean.append(dl)\n",
    "            doc_right_clean.append(dr)\n",
    "        elif (ll < 8 or lr < 8) and (abs(ll-lr) < 8):\n",
    "            doc_left_clean.append(dl)\n",
    "            doc_right_clean.append(dr)\n",
    "        elif verbose:\n",
    "            print(dl, '||', dr)\n",
    "        \n",
    "    print('remove mislength from langauge pair')\n",
    "    print('from {0} to {1}'.format(len(doc_left), len(doc_left_clean)))\n",
    "    \n",
    "    return doc_left_clean, doc_right_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove mislang pair\n",
    "def pair_mislang(doc_left, doc_right, lang_left, lang_right, model_path, kmost=2, verbose=False):\n",
    "    \n",
    "    res_left = get_lang(doc_left, model_path, kmost)\n",
    "    res_right = get_lang(doc_right, model_path, kmost)\n",
    "    \n",
    "    doc_left_clean = []\n",
    "    doc_right_clean = []\n",
    "    \n",
    "    for idx in range(len(doc_left)):\n",
    "        \n",
    "        rl = [l.split('__')[-1] for l in res_left[0][idx]]\n",
    "        rr = [l.split('__')[-1] for l in res_right[0][idx]]\n",
    "        \n",
    "        if (lang_left in rl) and (lang_right in rr):\n",
    "            doc_left_clean.append(doc_left[idx])\n",
    "            doc_right_clean.append(doc_right[idx])\n",
    "        elif verbose:\n",
    "            print(doc_left[idx], '||', doc_right[idx])\n",
    "    \n",
    "    print('remove mislength from langauge pair')\n",
    "    print('from {0} to {1}'.format(len(doc_left), len(doc_left_clean)))\n",
    "    \n",
    "    return doc_left_clean, doc_right_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# europarl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "europarl_en = load_text('./data/raw/europarl/europarl-v7.fr-en.en')\n",
    "europarl_fr = load_text('./data/raw/europarl/europarl-v7.fr-en.fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove duplicate from langauge pair\n",
      "from 2007723 to 1943690\n",
      "remove mislength from langauge pair\n",
      "from 1943690 to 1930782\n",
      "remove mislength from langauge pair\n",
      "from 1930782 to 1928347\n"
     ]
    }
   ],
   "source": [
    "temp_en, temp_fr = pair_deduplicate(europarl_en, europarl_fr)\n",
    "temp_en, temp_fr = pair_mislength(temp_en, temp_fr)\n",
    "temp_en, temp_fr = pair_mislang(temp_en, temp_fr, 'en', 'fr', './model/lid.176.bin', 2)\n",
    "europarl_en_clean, europarl_fr_clean = temp_en, temp_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr President, I would like to preface my few remarks by echoing comments made by other speakers in thanking Mrs Palacio for the work that she has done on this report. || Monsieur le Président, avant de formuler mes remarques, je voudrais me faire l'écho des commentaires faits par d'autres orateurs et remercier Mme Palacio pour le travail qu'elle a accompli en rédigeant ce rapport.\n",
      "It is not merely that she is not proposing any amendments - although that is an example that some rapporteurs might follow with advantage, rather it is because she has recognised the overriding importance of taking this legislation forward and putting it on the statute book. || Et ce n'est pas simplement parce qu'elle ne propose aucun amendement - bien qu'il serait avantageux pour certains rapporteurs de suivre cet exemple - mais plutôt parce qu'elle a reconnu qu'il était d'une importance primordiale de faire avancer cette législation et de l'inscrire dans les textes de loi.\n",
      "As has been mentioned this evening, e-commerce and online business are developing very rapidly and it is very important that we put in place a legislative framework in Europe within which it can develop and flourish. || Comme on l'a signalé ce soir, le commerce électronique et le commerce en ligne se développent très rapidement et il est crucial que nous mettions en place en Europe un cadre juridique qui lui permette de se développer et de s'épanouir.\n"
     ]
    }
   ],
   "source": [
    "sid, win = 45000, 3\n",
    "for idx in range(sid, sid+win):\n",
    "    print(europarl_en_clean[idx], '||', europarl_fr_clean[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_text(europarl_en_clean, './data/clean/europarl-enfr-clean.en')\n",
    "save_text(europarl_fr_clean, './data/clean/europarl-enfr-clean.fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# tatoeba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfBase = pd.read_csv('./data/raw/tatoeba/sentences.csv', sep='\\t', header=None, names=['label', 'lang', 'text'])\n",
    "dfBase = dfBase.set_index('label')\n",
    "dfLink = pd.read_csv('./data/raw/tatoeba/links.csv', sep='\\t', header=None, names=['ida', 'idb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# en fr sentences label\n",
    "label_en = set(dfBase[dfBase['lang']=='eng'].index.tolist())\n",
    "label_fr = set(dfBase[dfBase['lang']=='fra'].index.tolist())\n",
    "lang_pair = set()\n",
    "# get lang pair label\n",
    "for r in dfLink.itertuples():\n",
    "    if r[1] in label_en and r[2] in label_fr:\n",
    "        lang_pair.add((r[1], r[2]))\n",
    "    elif r[2] in label_en and r[1] in label_fr:\n",
    "        lang_pair.add((r[2], r[1]))\n",
    "lang_enfr = list(lang_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tatoeba has 231165 sentences pair for english and french\n"
     ]
    }
   ],
   "source": [
    "# extract lang pair\n",
    "tatoeba_en = []\n",
    "tatoeba_fr = []\n",
    "for lpair in lang_enfr:\n",
    "    tatoeba_en.append(dfBase.loc[lpair[0],'text'].strip())\n",
    "    tatoeba_fr.append(dfBase.loc[lpair[1],'text'].strip())\n",
    "print('tatoeba has {} sentences pair for english and french'.format(len(tatoeba_en)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We couldn't carry out our project because of a lack of funds. || Nous n'avons pu mener à bien notre projet à cause d'un manque de fonds.\n",
      "Yes, I have smoked crack cocaine. || Oui, j'ai fumé du crack.\n",
      "I don't have a prejudice against foreign workers. || Je n'ai pas de préjugé contre les travailleurs étrangers.\n"
     ]
    }
   ],
   "source": [
    "sid, win = 50000, 3\n",
    "for idx in range(sid, sid+win):\n",
    "    print(tatoeba_en[idx], '||', tatoeba_fr[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_text(tatoeba_en, './data/clean/tatoeba-enfr-clean.en')\n",
    "save_text(tatoeba_fr, './data/clean/tatoeba-enfr-clean.fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# jrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('./data/raw/jrc/alignedCorpus-en-fr.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jrc_en = []\n",
    "jrc_fr = []\n",
    "\n",
    "# extract and clean\n",
    "anti_dup = set()\n",
    "for t in root.findall('.//link'):\n",
    "    \n",
    "    # get text\n",
    "    \n",
    "    # s1 or s2 may contain p\n",
    "    if t.find('s1').find('p') is None:\n",
    "        sent_en = t.find('s1').text\n",
    "    else:\n",
    "        sent_en = ' '.join([p.text for p in t.find('s1').findall('p')])\n",
    "    if t.find('s2').find('p') is None:\n",
    "        sent_fr = t.find('s2').text\n",
    "    else:\n",
    "        sent_fr = ' '.join([p.text for p in t.find('s2').findall('p')])\n",
    "        \n",
    "    # clean\n",
    "    \n",
    "    # start or end space\n",
    "    sent_en = sent_en.strip()\n",
    "    sent_fr = sent_fr.strip()\n",
    "    \n",
    "    # useless line\n",
    "    if sent_en.startswith('Article ') or sent_fr.startswith('Article '):\n",
    "        continue\n",
    "    if ('%gt%' in sent_en) or ('%gt%' in sent_fr):\n",
    "        continue\n",
    "    if ('http://' in sent_en) or ('http://' in sent_fr):\n",
    "        continue\n",
    "    if ('https://' in sent_en) or ('https://' in sent_fr):\n",
    "        continue\n",
    "    if sent_en.startswith('[1]') or sent_fr.startswith('[1]'):\n",
    "        continue\n",
    "    if (sent_en.startswith('(') and sent_en.endswith(')')):\n",
    "        continue\n",
    "    if (sent_fr.startswith('(') and sent_fr.endswith(')')):\n",
    "        continue\n",
    "    if len(sent_en.split('|')) > 3:\n",
    "        continue\n",
    "    if len(sent_fr.split('|')) > 3:\n",
    "        continue\n",
    "    \n",
    "    # mismatch upper percentage\n",
    "    upper_en = sum([1 for c in ''.join(sent_en.split()) if c.isupper()]) * 1.0 / len(''.join(sent_en.split()))\n",
    "    upper_fr = sum([1 for c in ''.join(sent_fr.split()) if c.isupper()]) * 1.0 / len(''.join(sent_fr.split()))\n",
    "    \n",
    "    if abs(upper_en - upper_fr) > 0.5:\n",
    "        continue\n",
    "    \n",
    "    # sentence index\n",
    "    idx_flag = False\n",
    "    for idx in range(1, 6):\n",
    "        pfa = str(idx)+'.'\n",
    "        pfb = str(idx)+' .'\n",
    "        enj = sent_en.startswith(pfa) or sent_en.startswith(pfb)\n",
    "        frj = sent_fr.startswith(pfa) or sent_fr.startswith(pfb)\n",
    "        \n",
    "        if enj and frj:\n",
    "            sent_en = sent_en.split('.', 1)[1].strip()\n",
    "            sent_fr = sent_fr.split('.', 1)[1].strip()\n",
    "            break\n",
    "        \n",
    "        if enj != frj:\n",
    "            idx_flag = True\n",
    "            break\n",
    "    if idx_flag:\n",
    "        continue\n",
    "    \n",
    "    idx_flag = False\n",
    "    for lidx in ['a', 'b', 'c', 'd', 'A', 'B', 'C', 'D']:\n",
    "        \n",
    "        pfa = '('+lidx+')'\n",
    "        pfb = lidx+')'\n",
    "        enj = sent_en.startswith(pfa) or sent_en.startswith(pfb)\n",
    "        frj = sent_fr.startswith(pfa) or sent_fr.startswith(pfb)\n",
    "        \n",
    "        if enj and frj:\n",
    "            sent_en = sent_en.split(')', 1)[1].strip()\n",
    "            sent_fr = sent_fr.split(')', 1)[1].strip()\n",
    "            break\n",
    "        \n",
    "        if enj != frj:\n",
    "            idx_flag = True\n",
    "            break\n",
    "    if idx_flag:\n",
    "        continue\n",
    "    \n",
    "    idx_flag = False\n",
    "    for idx in range(1, 4):\n",
    "        \n",
    "        pfa = '('+'i'*idx+')'\n",
    "        pfb = 'i'*idx+')'\n",
    "        enj = sent_en.startswith(pfa) or sent_en.startswith(pfb)\n",
    "        frj = sent_fr.startswith(pfa) or sent_fr.startswith(pfb)\n",
    "        \n",
    "        if enj and frj:\n",
    "            sent_en = sent_en.split(')', 1)[1].strip()\n",
    "            sent_fr = sent_fr.split(')', 1)[1].strip()\n",
    "            break\n",
    "        \n",
    "        if enj != frj:\n",
    "            idx_flag = True\n",
    "            break\n",
    "    if idx_flag:\n",
    "        continue\n",
    "    \n",
    "    idx_flag = False\n",
    "    for lidx in ['- ']:\n",
    "        \n",
    "        enj = sent_en.startswith(lidx)\n",
    "        frj = sent_fr.startswith(lidx)\n",
    "        \n",
    "        if enj and frj:\n",
    "            sent_en = sent_en[len(lidx):]\n",
    "            sent_fr = sent_fr[len(lidx):]\n",
    "            break\n",
    "        \n",
    "        if enj != frj:\n",
    "            idx_flag = True\n",
    "            break\n",
    "    if idx_flag:\n",
    "        continue\n",
    "    \n",
    "    # replace special\n",
    "    sent_en = sent_en.replace('%quot%', '\"')\n",
    "    sent_fr = sent_fr.replace('%quot%', '\"')\n",
    "    \n",
    "    sent_en = sent_en.replace('º', 'o')\n",
    "    sent_fr = sent_fr.replace('º', 'o')\n",
    "    \n",
    "    \n",
    "    # append\n",
    "    if (sent_en not in anti_dup) and (sent_fr not in anti_dup):\n",
    "        anti_dup.add(sent_en)\n",
    "        anti_dup.add(sent_fr)\n",
    "        \n",
    "        jrc_en.append(sent_en)\n",
    "        jrc_fr.append(sent_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove mislength from langauge pair\n",
      "from 673595 to 669919\n",
      "remove mislength from langauge pair\n",
      "from 669919 to 626900\n"
     ]
    }
   ],
   "source": [
    "temp_en, temp_fr = pair_mislength(jrc_en, jrc_fr)\n",
    "temp_en, temp_fr = pair_mislang(temp_en, temp_fr, 'en', 'fr', './model/lid.176.bin', 2)\n",
    "jrc_en_clean, jrc_fr_clean = temp_en, temp_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall not issue the document referred to in Article 10 (1), final indent, of Directive 74/150/EEC in respect of a type of tractor, the operating space, access to the driving position, doors and windows of which do not comply with the provisions of this Directive; || ne peuvent plus délivrer le document prévu à l'article 10 paragraphe 1 dernier tiret de la directive 74/150/CEE pour un type de tracteur dont l'espace de manoeuvre, les facilités d'accès au poste de conduite, les portes et les fenêtres ne répondent pas aux prescriptions de la présente directive,\n",
      "may refuse to grant national type-approval in respect of a type of tractor, the operating space, access to the driving position, doors and windows of which do not comply with the provisions of this Directive. || peuvent refuser la réception de portée nationale d'un type de tracteur dont l'espace de manoeuvre, les facilités d'accès au poste de conduite, les portes et les fenêtres ne répondent pas aux prescriptions de la présente directive.\n",
      "COUNCIL DIRECTIVE of 16 June 1988 amending Directive 70/220/EEC on the approximation of the laws of the Member States relating to measures to be taken against air pollution by gases from engines of motor vehicles (Restriction of particulate pollutant emissions from diesel engines) (88/436/EEC) || DIRECTIVE DU CONSEIL du 16 juin 1988 modifiant la directive 70 /220/CEE concernant le rapprochement des législations des États membres relatives aux mesures à prendre contre la pollution de l'air par les gaz provenant des moteurs équipant les véhicules à moteur ( Limitation des émissions de particules polluantes par les moteurs diesel ) ( 88/436/CEE )\n"
     ]
    }
   ],
   "source": [
    "sid, win = 59000, 3\n",
    "for idx in range(sid, sid+win):\n",
    "    print(jrc_en_clean[idx], '||', jrc_fr_clean[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_text(jrc_en_clean, './data/clean/jrc-enfr-clean.en')\n",
    "save_text(jrc_fr_clean, './data/clean/jrc-enfr-clean.fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# giga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "giga_en = load_text('./data/raw/giga/giga-fren.release2.fixed.en')\n",
    "giga_fr = load_text('./data/raw/giga/giga-fren.release2.fixed.fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove duplicate from langauge pair\n",
      "from 22520376 to 19630451\n",
      "remove mislength from langauge pair\n",
      "from 19630451 to 18958975\n",
      "remove mislength from langauge pair\n",
      "from 18958975 to 18640137\n"
     ]
    }
   ],
   "source": [
    "temp_en, temp_fr = pair_deduplicate(giga_en, giga_fr)\n",
    "temp_en, temp_fr = pair_mislength(temp_en, temp_fr)\n",
    "temp_en, temp_fr = pair_mislang(temp_en, temp_fr, 'en', 'fr', './model/lid.176.bin', 2)\n",
    "giga_en_clean, giga_fr_clean = temp_en, temp_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He wants to understand how the process of this genetic re-creation can occur so quickly, and identify the cellular steps that transform it into a potentially fatal tumour. || Il veut comprendre comment le processus de cette recréation génétique peut être aussi rapide et déterminer les stades cellulaires qui conduisent à une tumeur potentiellement mortelle.\n",
      "Minister Alcock highlights the recipients of 19 new health research grants worth $6.2 million for Manitoba Backgrounder on Featured Researchers - Manitoba [ Press release 2005-13 ] Peacekeepers and mental health ",
      "Members of the Canadian Armed Forces are increasingly involved in peacekeeping operations, which can lead to emotional problems including depression, anxiety disorders and suicidal behaviour. || Le ministre Alcock souligne les titulaires de 19 nouvelles subventions de recherche en santé d'une valeur de 6,2 M$ pour le Manitoba Fiche d'information sur les chercheurs en vedette - Manitoba [ Communiqué 2005-13 ] Les membres des opérations de maintien de la paix et le traitement en santé mentale ",
      "Les membres des Forces armées canadiennes prennent de plus en plus part à des opérations de maintien de la paix, opérations qui peuvent entraîner des problèmes émotifs dont la dépression, des troubles anxieux et des comportements suicidaires.\n",
      "Heart repair and regeneration ",
      "Heart attacks damage functional tissue; the heart's ability to repair itself depends on its ability to awaken and attract cells that can divide and replace the lost muscle tissue. || La réparation et la régénération des tissus cardiaques ",
      "Les crises cardiaques endommagent les tissus fonctionnels; la capacité du coeur de se régénérer est tributaire de sa capacité à « réveiller » et à attirer des cellules capables de se diviser et de remplacer les tissus musculaires perdus.\n"
     ]
    }
   ],
   "source": [
    "sid, win = 1171100, 3\n",
    "for idx in range(sid, sid+win):\n",
    "    print(giga_en_clean[idx], '||', giga_fr_clean[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_text(giga_en_clean, './data/clean/giga-enfr-clean.en')\n",
    "save_text(giga_fr_clean, './data/clean/giga-enfr-clean.fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_en = load_text('./data/raw/un/undoc.2000.fr-en.en')\n",
    "un_fr = load_text('./data/raw/un/undoc.2000.fr-en.fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove duplicate from langauge pair\n",
      "from 12886831 to 9313528\n",
      "remove mislength from langauge pair\n",
      "from 9313528 to 9181938\n",
      "remove mislength from langauge pair\n",
      "from 9181938 to 9076185\n"
     ]
    }
   ],
   "source": [
    "temp_en, temp_fr = pair_deduplicate(un_en, un_fr)\n",
    "temp_en, temp_fr = pair_mislength(temp_en, temp_fr)\n",
    "temp_en, temp_fr = pair_mislang(temp_en, temp_fr, 'en', 'fr', './model/lid.176.bin', 2)\n",
    "un_en_clean, un_fr_clean = temp_en, temp_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were few established national mechanisms to implement policies and programmes for the girl child and, in some cases, coordination among responsible institutions was insufficient. || Les mécanismes nationaux nécessaires pour appliquer des politiques et programmes en faveur de la fillette sont rares et, dans certains cas, la coordination entre les entités compétentes s'est révélée insuffisante.\n",
      "Adolescents continue to lack the education and service needed to enable them to deal in a positive and responsible way with their sexuality. || Les adolescents continuent d'être privés de l'instruction et des services dont ils auraient besoin pour pouvoir assumer leur sexualité de manière positive et responsable.\n",
      "Since 1995, a number of issues have gained prominence and acquired new dimensions which pose additional challenges to the full and accelerated implementation of the Platform in order to realize gender equality, development and peace by Governments, intergovernmental bodies, international organizations, the private sector and non-governmental organizations as appropriate. || Depuis 1995, un certain nombre de questions ont pris une grande importance et acquis de nouvelles dimensions, ce qui pose un surcroît de difficultés pour la mise en oeuvre intégrale et accélérée du Programme d'action pour permettre aux gouvernements, aux organismes intergouvernementaux, aux organisations internationales, au secteur privé et aux ONG, selon les cas, de parvenir à l'égalité entre les sexes, au développement et à la paix.\n"
     ]
    }
   ],
   "source": [
    "sid, win = 271100, 3\n",
    "for idx in range(sid, sid+win):\n",
    "    print(un_en_clean[idx], '||', un_fr_clean[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_text(un_en_clean, './data/clean/un-enfr-clean.en')\n",
    "save_text(un_fr_clean, './data/clean/un-enfr-clean.fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
